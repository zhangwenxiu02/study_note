GAN

https://dl.acm.org/doi/10.1145/3503161.3548206

基于语言的迭代图像处理旨在根据用户的语言指令逐步编辑图像。现有的方法大多侧重于将新添加的视觉元素的属性和外观与当前指令保持一致。然而，随着迭代轮数的增加，这些方法无法保持指令与图像之间的一致性。为解决这一问题，我们提出了一种新颖的长短期一致性推理生成对抗网络（LS-GAN），它能增强对当前指令与先前对象的感知，并在不断迭代的情况下更好地保持与用户意图的一致性。具体来说，我们首先设计了一个上下文感知短语编码器（CPE），通过提取指令的不同短语级信息来学习用户意图。此外，我们还引入了长短期一致性推理（LSCR）机制。长期推理改进了模型的语义理解和位置推理能力，而短期推理则确保了根据语言指令构建视觉场景的能力。大量结果表明，LS-GAN 在对象识别和位置方面都提高了生成质量，并在两个公开数据集上取得了最先进的性能。

key words：terative instruction-based image manipulation, GAN, Long andshort term consistency reasoning



# GAN-based matrix factorization for recommender systems

https://dl.acm.org/doi/10.1145/3477314.3507099

生成对抗网络（GAN）于 2014 年提出，引发了人们对生成建模的新兴趣。它们立即在图像合成、图像到图像翻译、文本到图像生成、图像绘制等方面达到了最先进的水平，并被应用于从医学到高能粒子物理学等各种科学领域。尽管 GAN 广受欢迎，并具有学习任意分布的能力，但它尚未被广泛应用于推荐系统（RS）。 在这项工作中，我们提出了一种基于 GAN 的新方法，该方法在矩阵因式分解设置中学习用户和项目的潜在因素，以解决通用的 top-N 推荐问题。按照 CFGAN 为 RS 引入的向量式 GAN 训练方法，我们发现了将 GAN 用于 CF 时的两个独特问题。我们通过 RS 界的著名数据集对我们的模型 GANMF 进行了评估，结果表明它比传统的 CF 方法和基于 GAN 的模型都有所改进。通过对 GANMF 组件的消融研究，我们旨在了解我们的架构选择所产生的影响。最后，我们对 GANMF 的矩阵因式分解性能进行了定性评估。

关键词：collaborative filtering, matrix factorization, generative adversarialnetworks, autoencoder, feature matching

协同过滤、矩阵因式分解、生成式对抗网络、自动编码器、特征匹配

# A neuromorphic GAN system for intelligent computing on edge

https://dl.acm.org/doi/10.1145/3318216.3363334

最近，人工智能在向边缘设备发展方面取得了巨大成功。然而，涉及深度神经网络（DNN）的计算极其耗费资源和电力，成为边缘计算的一大挑战。基于可编程 ReRAM 的神经形态引擎为高效的 DNN 计算提供了机会；然而，在当前的研究中，训练过程中的内存利用率和通信延迟仍然是重大挑战，而且尚未得到解决。这一问题在具有复杂训练过程的 DNN 中变得更加严重，例如在边缘智能计算中被广泛采用的生成式对抗网络（GAN）。在这项工作中，我们在 ReRAM 神经形态引擎上设计了一个高效的 GAN 计算系统，采用在线训练框架、优化的后向计算和交叉并行计算流来高效执行训练过程，从而解决了这些难题。我们对系统性能进行了评估，并与传统的 GPU 加速器进行了比较，结果表明系统速度提高了 2.8 倍，能耗降低了 6.1 倍。

# PAR-GAN: Improving the Generalization of Generative Adversarial Networks Against Membership Inference Attacks

最近的研究表明，生成对抗网络（GAN）的泛化能力可能很差，因此容易受到隐私攻击。在本文中，我们试图从隐私保护的角度提高生成对抗网络的泛化能力，特别是在防御成员推理攻击（MIA）方面，MIA 的目的是推断特定样本是否用于模型训练。我们设计了一种 GAN 框架，即分区 GAN（PAR-GAN），它由一个生成器和多个在训练数据的不连续分区上训练过的判别器组成。PAR-GAN 的主要思想是通过近似训练数据所有分区的混合分布来缩小泛化差距。我们的理论分析表明，PAR-GAN 可以像原始 GAN 一样实现全局最优。我们在模拟数据和多个流行数据集上的实验结果表明，PAR-GAN 可以提高 GAN 的泛化能力，同时减少 MIA 引起的信息泄漏。适用于联邦学习

https://dl.acm.org/doi/epdf/10.1145/3447548.3467445

- 哈工大的

关键词：Generative Adversarial Networks, Membership Inference Attack,Generalization Gap生成式对抗网络、成员推理攻击、泛化差距

# T. Miyato, A. M. Dai, and I. Goodfellow, “Adversarial training methods for semi-supervised text classification,” 2017对抗扰动文献

# Distributed Learning based on Asynchronized Discriminator GAN for remote sensing image segmentation

DGAN由多个分布式判别器和一个中央生成器组成，仅使用DGAN生成的合成遥感图像来训练语义分割模型。基于DGAN，我们建立了一个由多个不同主机组成的实验平台，该平台采用Socket和多进程技术实现主机间的异步通信，并将训练和测试过程可视化。在 DGAN 训练过程中，节点之间交换的不是原始遥感图像或卷积网络模型信息，而是合成图像、损失和标记图像。因此，DGAN 很好地保护了原始遥感图像的隐私和安全。我们在三个遥感图像数据集（City-OSM、WHU 和 KaggleShip）上验证了 DGAN 的性能。在实验中，我们考虑了遥感图像在客户端节点中的不同分布。实验结果表明，DGAN 在不共享原始遥感图像或卷积网络模型的情况下，具有很强的分布式遥感图像学习能力。此外，与在所有客户端节点收集的所有遥感图像上训练的集中式 GAN 相比，DGAN 在遥感图像的语义分割任务中几乎可以达到相同的性能。

[Distributed Learning based on Asynchronized Discriminator GAN for remote sensing image segmentation (acm.org)](https://dl.acm.org/doi/epdf/10.1145/3571662.3571668)

DGAN、遥感图像、隐私

# FedCG: Leverage Conditional GAN for Protecting Privacy and Maintaining Competitive Performance in Federated Learning

联合学习（FL）旨在保护数据隐私，使客户能够在不共享其私人数据的情况下合作建立机器学习模型。最近的研究表明，在联合学习过程中交换的信息会受到基于梯度的隐私攻击，因此，人们采用了多种隐私保护方法来挫败这种攻击。然而，这些防御方法要么会带来数量级的计算和通信开销（如同态加密），要么会在预测准确性方面造成巨大的模型性能损失（如差分隐私）。在这项工作中，我们提出了一种新颖的联合学习方法 FEDCG，它利用条件生成对抗网络来实现高级别的隐私保护，同时还能保持有竞争力的模型性能。FEDCG 将每个客户端的本地网络分解为一个私有提取器和一个公共分类器，并将提取器保持在本地以保护隐私。FEDCG 不公开提取器，而是与服务器共享客户生成器，以聚合客户的共享知识，从而提高每个客户本地网络的性能。广泛的实验证明，与 FL 基线相比，FEDCG 可以获得有竞争力的模型性能，隐私分析表明 FEDCG 具有高级别的隐私保护能力。

https://www.ijcai.org/proceedings/2022/324

可信联邦学习，横向联邦学习中通过将生成对抗网络与分割学习相结合，在保护数据隐私的同时保持有竞争力的模型性能。

# Unlearning Protected User Attributes in Recommendations with Adversarial Training

[Unlearning Protected User Attributes in Recommendations with Adversarial Training | Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval](https://dl.acm.org/doi/abs/10.1145/3477495.3531820)

这些编码偏差会影响推荐系统（RS）的决策，使其进一步将提供给不同人群的内容分离开来，并引发有关泄露用户受保护属性的隐私问题。在这项工作中，我们研究了在保持推荐系统效率的同时，从推荐系统算法的交互表征中移除用户特定受保护信息的可能性和挑战。具体来说，我们在最先进的多VAE架构中加入了对抗训练，从而产生了一种新型模型--多项式似然对抗变异自动编码器（Adversarial Variational Auto-Encoder with Multinomial Likelihood，Adv-MultVAE），其目的是在保持推荐性能的同时去除受保护属性的隐含信息。我们在 MovieLens-1M 和 LFM-2b-DemoBias 数据集上进行了实验，并根据外部攻击者无法从模型中泄露用户性别信息的情况，评估了偏差缓解方法的有效性。结果表明，Adv-MultVAE 与基线 MultVAE 相比，在性能（与 NDCG 和 Recall 相比）略有下降的情况下，在很大程度上减轻了模型在这两个数据集上的固有偏差。

recommendation, adversarial training, gender bias, bias mitigation

[Adv-MultVAE：基于对抗学习的隐私保护推荐算法 - 隐私保护新闻推荐 - 新闻推荐 - 论文精读 | hang shun = 航 順 = 天官赐福，百无禁忌 (gitee.io)](https://jiang-hs.gitee.io/posts/b2c2f458/)

# Learning Fair Representations for Recommendation: A Graph-based Perspective

CCF-A

论文有两个要点，其一是**使用生成对抗网络(GAN)训练的滤波器对原始的用户－物品embeddings向量进行转换，以除去用户的敏感信息**(该论文假定原始嵌入算法不可修改，只能在已经生成的embeddings向量上做转换)；其二是**在GAN的优化目标函数(被称为价值函数)中加入用户－物品二分图的信息，以充分利用用户和物品的关系**。除此之外，该论文通篇都散发着**表示学习（representation learning）[2]** 思想的光辉。

作为人工智能的一项重要应用，推荐系统是最普遍的计算机辅助系统之一，可帮助用户找到潜在的兴趣项目。最近，研究人员对人工智能应用的公平性问题给予了极大关注。这些方法大多假定了实例的独立性，并设计了复杂的模型来消除敏感信息，以促进公平性。然而，推荐系统与这些方法有很大不同，因为用户和项目自然形成了用户-项目双向图，并且在图结构中具有协作相关性。在本文中，我们提出了一种基于图的新技术，用于确保任何推荐模型的公平性。这里的公平性要求是指在用户建模过程中不暴露敏感特征集。具体来说，给定任何推荐模型的原始嵌入，我们学习过滤器的组合，根据敏感特征集将每个用户和每个项目的原始嵌入转换为过滤后的嵌入空间。对于每个用户，这种转换是在以用户为中心的图的对抗学习下实现的，目的是在过滤后的用户嵌入和该用户的子图结构之间混淆每个敏感特征。最后，大量的实验结果清楚地表明了我们提出的公平推荐模型的有效性。我们在 https://github.com/newlei/FairGo 上发布了源代码。

[Learning Fair Representations for Recommendation: A Graph-based Perspective | Proceedings of the Web Conference 2021 (acm.org)](https://dl.acm.org/doi/10.1145/3442381.3450015)