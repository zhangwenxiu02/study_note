# Selective knowledge sharing for privacypreserving federated distillation without a good teacher

## Q:论文是做什么的，摘要第一段

虽然联邦学习（FL）有望在不泄露本地数据的情况下实现高效的协作学习，但它仍然容易受到白盒隐私攻击，受到高通信开销的影响，并且难以适应异构模型。联合蒸馏（FD）作为解决这些挑战的替代范例而出现，它在客户端之间传输知识而不是模型参数。然而，由于本地数据分布的变化以及缺乏训练有素的教师模型，出现了挑战，这导致了误导性和模糊的知识共享，从而显着降低了模型性能。为了解决这些问题，本文提出了一种选择性FD知识共享机制，称为选择性FD，分别从局部和整体预测中识别准确和精确的知识。在理论见解的支持下，实证研究表明我们的方法增强了 FD 框架的泛化能力，并且始终优于基线方法。我们期望我们的研究能够实现隐私保护、通信高效和异构自适应的联合训练框架。

## Q：什么是 Selective-FD模型

通过准确度和精确度来衡量联合蒸馏中的知识质量。准确的预测与真实标签相符，而误导性知识则不然。同时，精确的知识具有低熵，而模糊性则意味着高熵和不确定性。客户端选择器负责过滤掉不正确的本地预测，而服务器端选择器旨在消除不明确的知识。

Selective-FD 引入了一种不同的方法，在训练过程中共享知识而不是模型参数。这种替代方法有几个优点。首先，Selective-FD自然地适应异构模型，消除了本地模型共享相同架构的需要。其次，与 FedAvg 相比，Selective-FD 大大减少了通信开销，因为知识的大小明显小于模型。第三，Selective-FD提供了比FedAvg更强的隐私保证。本地模型可能包含来自私有数据集的编码信息，但其他客户端或服务器仍然无法访问。



硬标签传递知识



## Q:问题

- FL 中的定期模型交换需要随着模型大小的增加而增加的通信开销。这禁止在FL11,12中使用大尺寸模型，这严重限制了模型的精度。此外，标准的联邦训练方法强制本地模型采用相同的架构，这不能很好地适应配备不同计算资源的异构客户端13,14。此外，尽管原始数据不直接在客户端之间共享，但模型参数可以对有关数据集的私有信息进行编码，容易受到白盒攻击。
- 例如，在我们的图像分类任务实验中，现有的 FD 方法在高度非 IID 分布下几乎无法优于随机猜测。这项工作旨在解决没有好老师的 FD 知识共享的挑战，我们的关键思想是过滤掉误导性和模糊性的知识。我们提出了联邦蒸馏中的选择性知识共享机制（称为Selective-FD），以在联邦训练过程中识别准确且精确的知识。